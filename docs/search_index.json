[
["index.html", "Inquiry and Analysis in Biology Preface", " Inquiry and Analysis in Biology Preface "],
["overview.html", "1 Overview 1.1 Learning Objectives 1.2 Who This Book is For 1.3 About This Book", " 1 Overview 1.1 Learning Objectives Understand the nature of science as a way of knowing. Learn how to read scientific literature, evaluate and synthesize information, and to write clearly in scientific formats (e.g. lab reports, scientific papers, review papers). Learn how to interpret graphical information with statistical analyses, how to present data clearly in graphs and tables, and how to perform simple statistical analyses in R. 1.2 Who This Book is For This book is intended for undergraduate students who are writing their first scientific papers. The book was developed using materials from a course taught by Wesner to sophomores (mostly) at the University of South Dakota - BIOL 280 Inquiry and Analysis in Biology. We thank the 100’s of students that have taken this course previously. Many of the chapters of this book were written from drafts of course handouts. Feedback from the students was essential for improving the materials. This book was written with support from an Online Textbook Fellowship from the University of South Dakota. 1.3 About This Book Future biologists, doctors, and researchers need familiarity with how science proceeds and how it is communicated. Not having that knowledge is like getting a degree in music without learning how to read sheet music or knowing what a C major chord is. This book teaches you how to perform nearly all tasks that any researcher does: observe something, identify a question, gather data to test it, reach conclusions, share your conclusions, identify new questions. This process has been repeated millions of times over the last several centuries by all types of scientists. Often the results are interesting, but not groundbreaking. In rare cases, the results are groundbreaking – earth revolves around the sun, evolution by natural selection, genetic inheritance, biodiversity and ecosystem functioning. These findings make the news, the textbooks, social media, and other outlets. But first they are communicated among scientists. In universities, nearly all students learn the fundamentals of writing through introdctutory composition classes. These classes emphasize important components of rhetoric, grammar and writing structure. However, as students begin to write papers for their science professors, there is a frustrating realization that the traditions of creative writing that were learned in composition classes are not the same as the traditions of scientific writing that their science professors expect. Common challenges for students in learning scientific writing: 1) Using direct quotes 2) Failing to cite the literature 3) Unable to find relevant literature in the first place 4) Difficulty describing quantitative results 5) Difficulty placing results into a broader context These challenges do not arise from lack of intelligence and they do not mean that students are “bad” writers. They arise from a difficulty in understanding the culture shifts between writing for the Humanities and writing for the Sciences. To use another musical analogy, the difference between writing for the humanities and writing for the sciences is similar to the difference in playing improvisational jazz versus orchestral music. Both types of music have a common grammar, but they have vastly different approaches to how that grammar is expressed in song. In the same way, transitioning between writing for an English class and writing for a Biology class is not an easy task. Both writing styles are “correct”, yet each has its own traditions and expectations. This book will help you learn those traditions and expectations for scientific writing. Whether you do research at all in your career, you will be affected by those that do. Scientific research influences everything from flight delays, immunizations, cancer treatments, courtroom lighting, oil drilling, climate change, and how many commas to use in a sentence. All of it is guided by the same simple process that you will learn about in this book. We hope you enjoy the process. "],
["the-process-of-science.html", "2 The Process of Science 2.1 Learning Objectives 2.2 What is Science? 2.3 Science versus Non-science 2.4 Science Communication is Hard", " 2 The Process of Science 2.1 Learning Objectives Understand the nature of science as a way of knowing. Understand what distinguishes science from non-science 2.2 What is Science? If you want to study the effect of bloodletting on a condition, divide the patients into two groups, perform bloodletting only on one group, watch both, and compare the results. Al-Razi (Rhazes) 865 – 925 AD Does this quote, more than 1000 years old, represent the scientific method? You are likely aware of the basic components of the scientific method: Make an observation Pose a question Develop a testable hypothesis Design an experiment Collect data Analyze data Report your findings. That’s a lot of steps and this short quote doesn’t capture all of them, but it’s author implicitly recognizes some crucial pieces. The quote is most directly related to Designing an experiment. We can easily envision the basic structure of a medical trial that seeks to understand how bloodletting affects the average condition of the patients. Some of those patients would undergo bloodletting and some would not (…“divide the patients into two groups, perform bloodletting only on one group…”). Then, we would collect data from all patients and analyze them (…watch both, and compare the results.\"). I included this quote because I am always amazed by how relatable it is to the current high-tech world of science. We do the same things in our labs every day, in every discipline. So, yes, this is most certainly a representation of the scientific method. But, by itself, the quote would get an F if proposed by an undergraduate student in a science course. Why? Because it is only an invitation for more detail. For scientists, nearly every word sparks curiosity for more detail. Let’s pick out some examples: “If you want to study the effect of bloodletting…” — I know nothing about bloodletting. Does it involve a scapel? A tube? How much blood is let? Is it a fixed amount or does it change based on a person’s age, weight, size? “If you want to study the effect of bloodletting on a condition…” — What condition will you test? Will you measure how a single condition responds or multiple conditions? Does it matter how long they have had the condition? How do you know they have the condition to begin with? Is it reported from another doctor? Is it self-reported? “If you want to study the effect of bloodletting on a condition, divide the patients into two groups, perform bloodletting only on one group…” — Will the other group have a placebo? Will the bloodletting group know that they’re part of a research trial? Will that knowledge affect their response? Who will “perform the bloodletting”: the same doctor each time? If different people will perform the procedure, how will they be trained to maintain consistency? “If you want to study the effect of bloodletting on a condition, divide the patients into two groups, perform bloodletting only on one group, watch both…” — How? Will patients be in the hospital the whole time? If they’re allowed to go home, how do you monitor recovery? “If you want to study the effect of bloodletting on a condition, divide the patients into two groups, perform bloodletting only on one group, watch both, and compare the results.” — What will be compared? Recovery time? Whether they make a full recovery, regardless of time? The groups won’t be exactly the same no matter what you do, so how will you decide that bloodletting worked? Phew. We managed to get through the whole sentence, but this is exhausting. Imagine that your professor is responding this way about something you wrote. You may want to scream “OF COURSE THE CONTROL WILL GET A PLACEBO!!” or “BLOODLETTING IS 3,000 YEARS OLD, JUST LOOK IT UP ALREADY!”. But science is written precisely to address potential weak points. It can be frustrating, because you feel like some things are just obvious, so they can be implied, or they’re just common knowledge, so you don’t need to cite anything to support them. This is where science writing differs from other more casual forms of writing. Most of science writing can feel like you’re spending a large amount of cognitive effort explaining things that are obvious. 2.3 Science versus Non-science Scientific disciplines can seem stilting. Each branch of science is full of jargon and reading and conducting science often feels like learning a different language. Scientific discoveries are not made with sweeping insights generated geniuses pondering the depths of knowledge near the flickering light of a candle. They are made through lots of iterations of ideas that are continually subjected to the criticisms shown in the previous section. Science is a systematic way of discovering and organizing knowledge. It proceeds by examining testable hypotheses. Systematic and testable are key concepts that distinguish science from non-science. Systematic means that science is done according to pre-specified plans. Each scientific experiment takes months or years of planning. Consider the development of the COVID-19 vaccines. They represent perhaps the fastest, most well-funded, and most comprehensive effort to complete a scientific study that has ever been conducted. Thousands of people were dedicated to the single goal of developing and testing a vaccine in a systematic fashion. Even with all of this effort, it still took months to formulate a testing plan, followed by months of conducting trials, and months of analyzing the data. That is not a critique. It is one of the most exciting scientific endeavors of our life-time. Now consider the rest of us. Underfunded, working on projects when time permits. That kind of “regular” science easily takes years. Without a systematic plan of action, their is no guarantee that the science itself would ever be completed. Testable means that they hypotheses could be tested. For the vaccines, the testable hypothesis was that people who were vaccinated would get infected less often that people who were not vaccinated. That is testable, because we can follow each person and collect data on their infection status. Now suppose someone offered an alternative hypothesis that the ancient god of Covidea intervened to induce immunity in trial participants. How could we test that? We couldn’t, because we can’t measure the supposed causal agent (Covidea). It doesn’t mean that it’s impossible or even wrong, it just isn’t possible to know using scientific inference. 2.4 Science Communication is Hard Because science requires us to focus on the nitpicky details, it can often feel bland and formulaic, especially when reading the scientific literature. But there is also a benefit to having to constantly explain and justify your decisions as a scientist. First, it helps you to understand what you’ve actually done. As a scientist, I (Wesner) am a poor note taker. I always think that I’ll remember the temperature that I just recorded in tank 5. No need to get my notes wet now just to write down 23.5 degrees C. But I also know that a) I will most certainly have forgotten that number five minutes from now, and b) I will then have to explain why that number is missing from my data sheet in the paper that I’ll write 5 months from now. How can someone trust that I collected the data rigorously if I have to write: Data from tank 5 are missing because I forgot to write them down.. The other benefit of the details is that science writing has an egalitarian appeal to it. No matter how famous the scientist is, she cannot simply claim something as true without explaining the details. And on the flip side, no one is too junior to ask for proof. This requirement to document the details helps to prevent science from becoming overwhelmingly dictated by a few gatekeepers. That is not to say that science represents a utopia. Far, far from it. But requirements to “show your work” is one way to prevent it from becoming just another place where prestige and power matter more than truth. "],
["the-structure-of-scientific-writing.html", "3 The Structure of Scientific Writing 3.1 Learning Objectives 3.2 Pieces of Papers 3.3 Title 3.4 Abstract 3.5 Introduction 3.6 Methods 3.7 Results 3.8 Discussion 3.9 References 3.10 Tables 3.11 Figures 3.12 Putting it all together 3.13 How to Read a Scientific Paper", " 3 The Structure of Scientific Writing 3.1 Learning Objectives Understand the basic sections of scientific papers. Develop a plan for how to read science and write your paper. 3.2 Pieces of Papers There are millions of scientific papers in published journals and thousands of university lab courses that require scientific papers in some form. The vast majority have these sections: Title Abstract Introduction Methods Results Discussion References Tables Figures Later chapters of this book will discuss each of these in detail. In this chapter, we briefly introduce each section and then provide a guide for how to approach your writing project so that these rigid sections become a fluid and interesting scientific story. The lecture for this section is here: Lecture Link 3.3 Title Short and descriptive 3.4 Abstract One or two sentences that introduce the topic. One sentence that states your hypothesis. One sentence that briefly states what you did for methods. Two-three sentences of the main results with some quantitative information as needed (but no p-values). One or two sentences that summarize the main finding. 3.5 Introduction What big question are you going to answer for us? Why is this question important? Lots of references 4-5 paragraphs is usually plenty. 3.6 Methods What did you do to answer this important question? How did you analyze your data? Write what you did in a way that other people could repeat it. Doesn’t matter that your instructor knows what you did. It just matters that other scientists could understand it. Few references. 2-8 paragraphs is usually plenty. 3.7 Results Write what you discovered. Clear and simple and quantitative. Don’t interpret anything. Just report the basic results. Usually zero references here. 1-4 paragraphs is usually plenty. 3.8 Discussion Now you can interpret The most important result of this study was… Lots of references. 4-6 paragraphs is usually plenty. 3.9 References What is known and unknown? Establishes trust between writer and reader. Gives credit to other ideas. Pick one format (there are lots of ways to write citations) and stick to it. 3.10 Tables Summary statistics or raw data 3.11 Figures Make the font readable Make them as simple as possible The reader should be able to guess what the figure axes will be based on the written sections above. No surprises. 3.12 Putting it all together You are probably familiar with some or all of these sections of a scientific paper. The next challenge is harder - finding a way to put these sections together so that they result in an understandable and perhaps even enjoyable thing to read. That is the hard part, and it’s why you’re taking this class or reading this book. Here are some tips to get you started. Hourglass Structure Think of a scientific paper as having a beginning that sets out the broad ideas, a middle that has all of the technical details, and an end that leaves you with a core take-home message. A common way to visualize that is with an hourglass in which each each section of the paper moves from top to bottom (Fig. 1). The narrower sections have technical details that are relevant to your specific study. The broader sections relate those details to broader ideas. Often it can be easier to write the middle parts first. Figure 3.1: The hourglass structure of a scientific paper. The width of the hourglass reflects the purpose of each secion. The overall paper leads the reader from a broad concept to specific methods and results. Then it tells the reader how those specific results have changed our understanding of the broader concept in the introduction. Figures First One of our favorite ways to start writing a paper is to not write at all, but instead to work on the figures first. By figures, we mean the plots (or charts or data visualizations, etc) that show your scientific results. Here’s an example using a manuscript that one of us wrote (Wesner et al. 2020). Figure 3.2: The final paper for Wesner et al. 2020 had lots of technical details and broader context about COVID hospitalizations (left). But it started with only a single figure (right). Figure 3.3: The initial figure. We made this first and then wrote the rest of the paper around it. We spent a lot of time thinking about how to make this figure, because we used it to guide our writing. A well-made figure is more than just a visualization. It it also an outline for the paper itself. Here are some examples, linking parts of the graph to sections of the written text. y-axis The y-axis says “Cumulative Hospitalizations”. As a reader, if this figure was all we had seen, we could deduce that the paper had something to do with hospitalization trends over time. That’s not trivial. There are millions of scientific papers published each year on a vast array of disciplines (biology, physics, math, sociology, etc). With just the y-axis here, we now know that this paper is probably in the field of medicine or public health. The axis also starts at zero, so we can surmise that this study is measuring hospitalizations at the beginning of whatever is causing them. x-axis The x-axis has abbreviations for seven months, so we can assume that one predictor variable here is time and that the duration of the study is less than one year. key There are three time trends presented. One of them is for All of South Dakota. The others are for a county (Minnehaha County) and everything Outside of Minnehaha County. As a reader, we would use this information to guide us by finding the definitions of these groups in the text. panels The three time trends are presented across two models (Model 1 and Model 2), shown in the upper and lower panels. We can’t tell much about those models from the plot alone, but this gives us something to search for in the text. data The plot appears to show individual data points, presumably of the number of cumulative hospitalizations on each day. If we counted them all up, we could know exactly how many data points are in the analysis. fitted lines Corresponding to the data are a green, orange, or purple line with some shading. It is not clear from the plot along what these represent, and there is an odd-looking change in the shading after the data points. Even from this seemingly simple plot, we can glean a lot about the study before we’ve ever read a word of the paper. But there is a lot we still don’t know. Who is being hospitalized? What are they being hospitalized for? What are the two models? What’s up with the change in shading after the data end? As a writer, it is your job to explain these things in the text. A well-written paper provides details and context in the written sections of the paper that make it clear why the study was done (and why the plot is important to understand). Here are some examples. Title: Forecasting hospitalizations due to COVID-19 in South Dakota, USA. The title sheds a lot of light on the figure. We can assume that the y-axis in the figure is probably hospitalizations of COVID-19 patients in South Dakota. Abstract: Anticipating the number of hospital beds needed for patients with COVID-19 remains a challenge. Early efforts to predict hospital bed needs focused on deriving predictions from SIR models, largely at the level of countries, provinces, or states… The first two sentences of the abstract give further clues as to why the y-axis in the figure is important to know about. We want to know about hospitalizations COVID-19 so that we can better anticipate the health care infrastructure that might be needed. According to the authors, doing that is a “challenge”, and other studies have addressed that challenge in varying ways. Introduction: Here are the first sentences of each paragraph of the introduction. The novel coronavirus (SARS-CoV-2) was first detected in December 2019 in Wuhan, China and has since spread globally. The disease is caused by SARS-CoV-2… Predicting hospitalization needs due to COVID-19 may be particularly challenging in rural areas. For example, relative…. To our knowledge, there are no published studies that model hospitalizations due to COVID-19 in rural and low resource settings. Here, we modeled cumulative hospitalizations in an urban (Minnehaha) versus rural population within South Dakota using a Bayesian non-linear Weibull function. Because early predictions… From skimming just the first sentences of the introduction, we’ve discovered that the study is important (according to the authors, anyway) because it represents hospitalization trends in an urban (Minnehaha) and rural setting. This helps to explain the key in the plot above. We shouldn’t just take the author’s word for it. If we were skeptical about why this is important to study, then we could find more justifications in the rest of the introduction. But scanning the first sentences gives us a quick way to judge the paper’s context. Methods: We fit the Weibull function to two sets of data that describe 1) the cumulative hospitalizations for the state of South Dakota and 2) the cumulative hospitalizations for subgroups of Minnehaha County and the rest of South Dakota. This sentence from the methods resolves the two panels. Now we know that the authors fit the data in two ways and that model 2 appears to use data that are subgroups of model 1. Results: At the state level, model 1 predicted a total of 876 hospitalizations (median) in South Dakota (90% CrI: 834-926, Table 2). The inflection point was predicted at 37 days after the first hospitalization, suggesting that the peak rate of hospitalizations occurred around April 20, 2020 (Table 2). In contrast, the model with group-level effects clearly showed that hospitalizations trends differed in Minnehaha County verses the rest of South Dakota… The results section here is three paragraphs long, and we’ve only pasted a few sentences from it. In the results, we can expect to find quantitative summaries that describe what we see in the graph. Discussion: The most important result of this study is that modeling trends separately in urban versus rural parts of a state population reveal different projections of cumulative hospitalizations than if modeled only using state-level data. In particular, the model… The discussion continues to provide context for the details in the rest of the paper. Now we can see what the authors think is the most important result, and how the patterns in the plot reinforce that result. We don’t have to agree with this. There are other parts to the paper and maybe we think those are more important…or that the paper is not really interesting at all. That is all fine. The main point is that we are able to judge the work based on clearly written text. This method - Figures First - is helpful in two ways. 1) It helps us to organize our writing, and 2) It helps us to quickly read and understand other scientific papers. Try it out! 3.13 How to Read a Scientific Paper The same features that help you write a scientific paper can also help to read one. Here are some tips that no one ever told us as undergraduates: 3.13.1 You don’t need to start at the beginning Just because a scientific paper starts with an Introduction doesn’t mean you need to read that part first. In our own reading, we often do this: Read the abstract and look for the main conclusions Look at the figures or tables. Are the main conclusions obvious in the figures or tables? If not, there is reason to worry. For example, if the abstract says “Insect abundance declined by 40% in the acid treatment relative to the control”, then we better be able to find a figure that shows insect abundance on the y-axis and the two treatments (control and acid) on the x-axis. If we see instead a figure with insect diversity on the y-axis and three treatments on the x-axis, then we know this paper is going to be difficult to understand. Maybe we should move on. After checking the abstract and the figures, we then read the introduction. It should tell us why the authors think this study is important. If we were reading the paper to learn about gene methylation, but the introduction is focused on a statistical procedure, then perhaps this paper isn’t going to answer the question we thought. Maybe we should move to a different paper. If we’ve committed to the paper, then we read the main results section and perhaps skim the discussion, looking for clues as to what the most important findings are and how they generate new knowledge. Finally, we parse the methods and analyses. Do we agree with these methods? Did they reflect the goals of the study? Do the analyses make sense? Sometimes we discover that the methods are faulty, even if the paper is in a peer-reviewed journal. If we like the conclusion, but disagree with the methods, then maybe the conclusion is wrong, too. If all of the above boxes check out, then we can decide to use that paper in our own work and cite it. 3.13.2 It doesn’t need to take forever to read a paper Once you get a feel for parsing papers, then you can usually proceed through the steps above pretty quickly. Often we might skim 4-5 papers before finally finding one that reports on a topic we’re interested in. Of those, we might fully read only a handful of the most relevant papers. The whole process of deciding on a paper can take just a few minutes. In fact, you can probably tell within 30-seconds whether you want to commit more time to the paper or move on. 3.13.3 You don’t need to understand every word You will rarely read a scientific paper in which you understand everything right off the bat. For one of us (Wesner), our field of study is insect and fish ecology. When reading papers in our expertise, we can usually understand them pretty easily, but only after doing it repeatedly over 15 years. But every other paper in a new discipline has new terminology. It’s slower for us. That’s OK. Don’t get caught up in the jargon. You can learn that later. If it seems important to know right away, then just look it up. Otherwise, get comfortable with not knowing everything. When reading a paper, focus on the broad picture. Look at the discussion to see what the authors thought was important. If it isn’t clear from the discussion, then maybe the authors themselves don’t actually know what was important. Move on to a different paper and come back again later. "],
["introduction-to-r.html", "4 Introduction to R 4.1 Learning Objectives 4.2 R and RStudio 4.3 How to Use This Chapter 4.4 Data Analysis Workflow 4.5 Getting Started in RStudio 4.6 Why to Code Instead of Click", " 4 Introduction to R 4.1 Learning Objectives Be able to download and open R and RStudio. Understand how to import data to R. Understand how to create a graph in R. Link to Lecture Links to Tutorials Importing data into R Transforming data from wide to long format (Tidying) Visualization Model - linear regression Model with merged data (merging two data sets and running a linear regression) 4.2 R and RStudio So far we’ve discussed the nature of science and the structure of scientific papers. Now we’re going to introduce a central method that is required of most modern science: scientific computing. It is almost impossible to conduct science without a computer, especially since we need to analyze data. We also need to store the data, organize it, plot it, summarize, and report it. Lots of tools do that. In this book, we use the computing software R (???). It is among the most popular programs for analyzing scientific data and it is designed specifically for the workflow we use in this book. It is also free. Here’s how you get it. Download R: (https://mirror.las.iastate.edu/CRAN/). Follow the link above and choose your operating system - Linux, Mac OS, or Windows Download RStudio: (https://rstudio.com/products/rstudio/download/#download) All of the examples in this book are generated using R. Actually, that’s not quite correct. While R is the workhorse, the examples in this book are generated through an interface to R called RStudio (???). R looks like this: Download only RStudio looks like this: Download, open, and use Once you’ve downloaded both programs, you’ll only need to open RStudio. It automatically uses R in the background. It is possible to do everything only in base R, but we prefer RStudio as a more user-friendly interface.1 4.3 How to Use This Chapter This book is not meant as a stand-alone R reference. It is meant as a companion to university-level labs and lectures, in which students can work through examples with an instructor or TA nearby to fill in the gaps and troubleshoot. When starting R, these are the types of questions many students have: “Is this the right program?” “What is a script again?” “How do you make the arrow?” “What is that squiggly sign?” “I ran the code and nothing happened…” In other words, we expect students to have lots of questions in this new and unfamiliar environment. Everyone started this way and the easiest way to find the answers is to ask an expert. However, there are lots of excellent R guides out there for students who are interested in learning more detail. Here are a few of our favorites: R for Data Science (free) - https://r4ds.had.co.nz/ (???) The R Book (???) Getting Started with R: An Introduction for Biologists (???) Data Visualization: A Practical Introduction (???) dplyr and tidyr cheatsheets - (https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) ggplot2 cheatsheet - (https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) 4.4 Data Analysis Workflow In this book, we focus on learning a few fundamental tasks that are common to the workflow of most data science projects (Wickham et al. 2019). Nearly every study that includes data has a workflow similar to that above. We gather data, get it into a program (Import), get it in the right format (Tidy), and then analyze it with plots (Visualize), Models, Transformations, etc. When we’ve finished, we communicate the results to our peers. You’ll learn how to complete these steps in R because its designed specifically for this type of workflow. But the workflow applies regardless of the software you use. 4.5 Getting Started in RStudio Before the fun stuff happens, we need to determine where things will be saved on our computer. If you’d prefer to skip this step, that is OK. Just be prepared for certain doom. 4.5.1 Create a folder on your computer for your analyses For example, if this is for a class called Biology 280, you might create a folder called BIO280_R. If you have data to analyze (like an Excel file or a .csv), save it in this folder as well. 4.5.2 Open RStudio Click the RStudio icon 4.5.3 Create a project File -&gt; New Project… -&gt; Existing Directory -&gt; Browse -&gt; [NAME OF YOUR FOLDER] You only need to do this once. After you create a project, all of the work you do within that project (data analysis, graphs, text) will be saved in it. If it all goes well, you should see a screen like this, with the name of your project in the upper right hand corner. 4.5.4 Open a script File -&gt; New File -&gt; R Script or ctrl+shift+N You should now see a screen like the one below, with four windows. The window on the lower right shows all of the Files in the folder you created on your computer. If you add something to that folder from outside of R, it will show up here as well. The window on the upper right shows your Environment. When you create something in R, like a new data frame or a plot, it will show up in the Environment (But it won’t be saved. More on that later). The window on the upper left shows your Script. This is where you tell R what to do. The window on the bottom left is the Console. It keeps a running list of all of the procedures you perform. For example, if you run code in the script, it will show up here. When something goes wrong, you’ll also see the error message here. 4.5.5 Install a package Click anywhere on the script window so that you see the flashing prompt. Type the code below and then type ctrl+enter. (NOTE: If you just hit enter without adding ctrl, it won’t work. It will just move you to the next line. Get in the habit of typing ctrl+enter to run your code). Like this: The code above tells R to install a package called tidyverse. You only have to do this once. After it’s installed, it will always be available when you open R, but you’ll have to tell R when you want to use it each time by typing library(tidyverse). Packages are bits of code that someone wrote and then converted into a series of shortcuts. R has 1000’s of packages for just about any task you can think of. The tidyverse package actually contains a bunch of other packages within it. As a result, when you install it for the first time, it will generate a lot of activity in your console, with red text and “https://..” links all over the place. That is all normal. Just give it a few minutes. You’ll know it’s done when you see the chevron &gt; in the console. 4.5.6 Your first script Now you are ready for the fun parts. To begin coding your first script, we are going to take an unorthodox approach. Instead of starting with first principles, we’ll start with the Visualize and Model steps from the workflow and then deconstruct that to learn the principles. Copy the code below and paste it in your script. Then run the code (by clicking ctrl+enter from the first line down). Do not try to interpret it yet. There is a lot going on here. We’ll break it down next. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) # make the data and &quot;model&quot; the mean and sd. d &lt;- mtcars %&gt;% group_by(cyl) %&gt;% mutate(mean = mean(mpg), sd = sd(mpg)) #plot the data ggplot(data = d, aes(x = cyl,y = mpg)) + geom_point(shape = 21) + geom_pointrange(aes(y = mean, ymin = mean-sd, ymax = mean+sd)) + labs(y = &quot;Miles Per Gallon&quot;, x = &quot;Cylinders&quot;) Here is what you just did: Loaded the tidyverse package. Created a data frame d that was a modified version of the data frame mtcars. Added two new columns to d: one containing the mean mpg for each type of cylinder and another containing the standard deviation. Plotted miles per gallon as a function of cylinders as raw data. Added a mean and standard deviation to the plot. Modified the axis names. If you’re a normal person, this should all be mysterious. Here’s the good news. The code above is about as complex as we will get in this book. It is also modular. That is crucial. It means that you don’t have to know every step to get started. Each batch of code that precedes %&gt;% or + will run by itself. Let’s break the code down into individual components: 1) Loaded the tidyverse package. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) What it does This code uses the function library() to load a package called tidyverse. The rest of the code depends on loading this package first. Did it work? Check the output in the console (lower left window). Red text is normal. It does not necessarily mean there is an error. If you see the prompt &gt;, that is a good sign. If you see words like \"there is no package called…\", \"Error…\", \"failed…\", then it probably didn’t work. Things to check if it doesn’t work Did you install the package first? Did you misspell anything? Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? 2) Created a data frame d that was a modified version of the data frame mtcars. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) d &lt;- mtcars What it does This code creates a data frame called d that contains all of the data that are in mtcars. A data frame is just a table with rows and columns. Try running View(mtcars) and you’ll see what the data frame looks like. mtcars is one of many data frames that are built in to R. It contains data on things like miles per gallon, weight, and horsepower for different types of cars. The symbol &lt;- is how we assign bits of code to objects in R. It’s a combination of the lesser than sign &lt; and the minus sign -. You will use this symbol all the time. Did it work? Do you see an object named d in the Environment window (upper right) that has “32 obs. of 11 variables”? If not, it didn’t work. Visually, the d in the Environment window is the only thing that will automatically show up if it worked. Another way to check is simply to view the data frame, like this: head(d) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 This shows a snapshot of the first few rows of the data frame that exists in the object d. It is essentially the same as any other spreadsheet you might make in another program, like Excel. Each row contains information on mpg, cylinders (cyl), horsepower(hp), etc. for each type of car. You can isolate individual columns: ## mpg cyl ## Mazda RX4 21.0 6 ## Mazda RX4 Wag 21.0 6 ## Datsun 710 22.8 4 ## Hornet 4 Drive 21.4 6 ## Hornet Sportabout 18.7 8 ## Valiant 18.1 6 Or check the types of columns: ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... This shows that the object d is a data frame with 32 observations (rows) of 11 variables (columns). It also lists the variables and gives a preview of the first 10 rows. [Note: instead of a data frame, you might see the word tibble. That is another name for a data frame used by the tidyverse package. It has some important distinctions, but they are not relevant for this chapter]. Things to check if it doesn’t work Did you misspell anything? Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? Is there a space in the arrow &lt; -? There shouldn’t be. Challenges Give the data frame a different name other than d. Select other columns using the select() function. 3) Added two new columns to d: one containing the mean mpg for each type of cylinder and another containing the standard deviation. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) # make the data and &quot;model&quot; the mean and sd d &lt;- mtcars %&gt;% group_by(cyl) %&gt;% mutate(mean = mean(mpg), sd = sd(mpg)) What it does This code adds a column summarizing the mean and sd of mpg for cars with different numbers of cylinders. We also have a new symbol %&gt;% called a “pipe”. You can either type it directly or use a shortcut ctrl-shift-m. Think of it as a way of telling R “and then…”. In sentence form, the code is saying this. d &lt;- mtcars %&gt;% create a data frame called d that contains all of the data that are in mtcars and then… group_by(cyl) %&gt;% assign each type of cylinder to a group and then… mutate(mean = mean(mpg), sd = sd(mpg)) create a new column called mean that contains the mean mpg’s for each type of cylinder. Also create a new column called sd that contains the standard deviation for each type of cylinder Did it work? Check the columns again with str(). Do you see the columns mean and sd now? Do you see the odd addendum that starts with “-attr(*,”groups“)…”? If so, then it worked. ## tibble [32 x 13] (S3: grouped_df/tbl_df/tbl/data.frame) ## $ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num [1:32] 160 160 108 258 360 ... ## $ hp : num [1:32] 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num [1:32] 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num [1:32] 16.5 17 18.6 19.4 17 ... ## $ vs : num [1:32] 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num [1:32] 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ... ## $ mean: num [1:32] 19.7 19.7 26.7 19.7 15.1 ... ## $ sd : num [1:32] 1.45 1.45 4.51 1.45 2.56 ... ## - attr(*, &quot;groups&quot;)= tibble [3 x 2] (S3: tbl_df/tbl/data.frame) ## ..$ cyl : num [1:3] 4 6 8 ## ..$ .rows: list&lt;int&gt; [1:3] ## .. ..$ : int [1:11] 3 8 9 18 19 20 21 26 27 28 ... ## .. ..$ : int [1:7] 1 2 4 6 10 11 30 ## .. ..$ : int [1:14] 5 7 12 13 14 15 16 17 22 23 ... ## .. ..@ ptype: int(0) ## ..- attr(*, &quot;.drop&quot;)= logi TRUE Things to check if it doesn’t work Did you load the library library(tidyverse)? The pipes %&gt;% only work if the tidyverse package is loaded. Did you misspell anything? Did you type out “cylinders” instead of using “cyl”? Computers don’t know those are related. Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? Is there a space in the arrow &lt; - or the pipes % &gt;%? There shouldn’t be. Did you put the package in quotes when calling the library() function: library(\"tidyverse\")? Challenges Summarize mpg by the number of gears instead of cylinders Add a column that calculates the median in addition to the mean and sd 4) Plotted miles per gallon as a function of cylinders as raw data. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) # make the data and &quot;model&quot; the mean and sd d &lt;- mtcars %&gt;% group_by(cyl) %&gt;% mutate(mean = mean(mpg), sd = sd(mpg)) #plot the data ggplot(data = d, aes(x = cyl,y = mpg)) + geom_point(shape = 21) What it does This code uses the powerful plotting package called ggplot2 (???). It included when you installed the tidyverse. The “gg” stands for “The Grammar of Graphics” (???), a fundamental set of principles for producing just about any plot you can think of (and rules for why some types of plots are better than others). Making anything with ggplot2 usually requires at least two things: 1) a call to ggplot(...) where we specify the data along with the x and y axes or other aesthetics, and 2) a call to geom_…, where we tell ggplot2 how to plot the data. There are lots of geoms, as you can see in this cheatsheet (https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf). For most practices in this book, we will use geom_point(), which simply adds a dot for each x-y coordinate that we specified in the aes() function. Once we have our base plot, everything else is added with +. This can be a point of confusion. The + has a similar meaning as the pipe %&gt;%, but ggplot2 only uses +. Accidentally typing %&gt;% instead of + is a common mistake even for experienced coders (like authors of textbooks about data analysis). You can see the iterative nature of ggplot by breaking it down further, adding one thing at a time. Did it work? The plot above should appear in the plot window (lower right). Things to check if it doesn’t work Did you leave a hanging plus + at the end of the code? If so, remove it. Did you write ggplot2() instead of ggplot()? Did you remember to assign the x and y axes within the aes() function? Did you put a pipe %&gt;% instead of a plus +? Did you misspell anything? Did you type out “cylinders” instead of using “cyl”? R doesn’t know those are related. Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? Is there a space in the arrow &lt; - or the pipes % &gt;%? There shouldn’t be. Did you put the package in quotes when calling the library() function: library(\"tidyverse\")? Did you load the library library(tidyverse)? The pipes %&gt;% only work if the tidyverse package is loaded. Challenges Assign a different y variable Change the shape In addition to shape, make the colors green (HINT: see the cheatsheet (https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)) 5) Added a mean and standard deviation to the plot. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) # make the data and &quot;model&quot; the mean and sd d &lt;- mtcars %&gt;% group_by(cyl) %&gt;% mutate(mean = mean(mpg), sd = sd(mpg)) #plot the data ggplot(data = d, aes(x = cyl,y = mpg)) + geom_point(shape = 21) + geom_pointrange(aes(y = mean, ymin = mean-sd, ymax = mean+sd)) What it does The new geom geom_pointrange() adds the mean and standard deviation to the plot. If we only typed geom_pointrange(), it wouldn’t work. That’s because the geom requires three values that we haven’t assigned yet: y, ymin, and ymax. In this case, we want y to be the mean of each group. We want the error bar to range from ymin to ymax. ymin is the mean minus the standard deviation for each group mean-sd. ymax is the mean plus the standard deviation mean+sd. With those values, ggplot draws a line from ymin to ymax. Did it work? The plot above should appear in the plot window (lower right). Things to check if it doesn’t work Did you leave a hanging plus + at the end of the code? If so, remove it. Did you write ggplot2() instead of ggplot()? Did you remember to assign the x and y axes within the aes() function? Did you put a pipe %&gt;% instead of a plus +? Did you misspell anything? Did you type out “cylinders” instead of using “cyl”? R doesn’t know those are related. Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? Is there a space in the arrow &lt; - or the pipes % &gt;%? There shouldn’t be. Did you put the package in quotes when calling the library() function: library(\"tidyverse\")? Did you load the library library(tidyverse)? The pipes %&gt;%only work if the tidyverse package is loaded. 6) Modified the axis names. #Copy this code, paste it in your script, and run it. #load a package library(tidyverse) # make the data and &quot;model&quot; the mean and sd d &lt;- mtcars %&gt;% group_by(cyl) %&gt;% mutate(mean = mean(mpg), sd = sd(mpg)) #plot the data ggplot(data = d, aes(x = cyl,y = mpg)) + geom_point(shape = 21) + geom_pointrange(aes(y = mean, ymin = mean-sd, ymax = mean+sd)) + labs(y = &quot;Miles Per Gallon&quot;, x = &quot;Cylinders&quot;) What it does The function labs() replaces the title of the x and y axis with whatever we put in quotes. Did it work? The plot above should appear in the plot window (lower right). Things to check if it doesn’t work Did you remember the comma? Did you switch the x and y? Did you leave a hanging plus + at the end of the code? If so, remove it. Did you write ggplot2() instead of ggplot()? Did you remember to assign the x and y axes within the aes() function? Did you put a pipe %&gt;% instead of a plus +? Did you misspell anything? Did you type out “cylinders” instead of using “cyl”? R doesn’t know those are related. Did you add a capital letter somewhere? Did you hit enter instead of ctrl-enter? Is there a space in the arrow &lt; - or the pipes % &gt;%? There shouldn’t be. Did you put the package in quotes when calling the library() function: library(\"tidyverse\")? Did you load the library library(tidyverse)? The pipes %&gt;% only work if the tidyverse package is loaded. Challenges Rename the x and y axes Add a title within the labs() function using title = \"put your title here\" 4.5.7 Importing your own data to RStudio To get your own data into R, first save the data into the same folder as your project. Look in the lower right panel of RStudio. Click on “Files”. Do you see the data set you saved? Click on it and choose Import Dataset…. Like this: After you click Import Dataset…., you’ll see a preview of your data set like this: Stop here and check the preview. Does everything look right? Are the column names correct? If not, you might need to check the box for “First Rows as Names” on the lower left. From here, you have two options. 1) Click “Import”, or 2) Copy the code in the Preview Code box, cancel the preview, and paste the code into your script. We strongly recommend the second option. Clicking will work, but if you come back to your script and need to reload the data, you’ll have to do this process again. If you instead copy the code and paste it into your script, then your code becomes self-contained and you won’t forget any steps in the future. Here is where you can copy from. We don’t copy the View() part, but you can if you want: Then paste it at the beginning of your script and run it. Our data set is called continents. Yours will probably be different, though. Do you see the name of your data set in the upper right panel? If so, success! If not, re-try the steps above or ask your instructor. You are now ready to practice the coding you’ve learned on your own data set. 4.6 Why to Code Instead of Click R is a programming language, which means that it can only do what you tell it to do by typing. RStudio has a few clickable shortcuts, but it still requires nearly everything to be typed into a script. There are other programs that conduct statistical and graphical analyses without using code. We choose to use R instead for several reasons. Clicking Isn’t Actually Easier Undergraduates are incredibly savvy with some aspects of computers, particularly in nagivating social media platforms. But in our experience, students often struggle with even rudimentary tasks in programs that professors think are easy, such as Microsoft Excel or SPSS. These programs have their own bewildering array of shortcuts and buttons (Nash 2008). For example, while this Excel function might make perfect sense to a seasoned user =STDEV.P(A$1:A$7) it can be just as confusing to a new student as the similar function in R sd(data$column). Similarly, while it may seem easier to run an ANOVA in SPSS by simply clicking the ANOVA button, this too is often misleading. Having helped students that are part way through a project in SPSS or other clickable programs, we almost always have to start their entire analysis over when a problem arises. The reason is that, by the time the ANOVA button is clicked, there have already been a series of steps in data preparation and uploading that might have generated a problem. In R, we can find these problems easily, because the script leaves a breadcrumb trail of each step. In non-scripting programs, there are no breadcrumbs, so solving the problem becomes much more complicated. And no matter what program you use or how simple your data seems, there will be problems to solve. Data Ethics A basic requirement in modern science is that the results of scientific findings could be reproduced by someone else. There are two levels to this. The first level of reproducibility is the description of the experimental approach, which is contained in a Methods section in a scientific publication. This ensures that someone else could read a Methods section and reproduce the steps of the experiment exactly without having to ask the author (who may no longer be alive or just doesn’t respond to email). The second level of reproducibility is in the analysis of a data set presented in a scientific publication. All analyses involve myriad human decisions. For example, what do we do with outliers (extreme data values that may be real or may be a result of data entry error or errors in the instruments)? What if half of our fish died in the middle of an experiment? Should we replace them with new ones? There are no easy answers to these questions. Each experiment has its own quirks and they will all involve subjective decisions by the scientist. What do we do about these subjective decisions? The golden rule is to be transparent about them. First, describe them in the Methods and provide a justification for them. Second, always include a way for readers to easily find the raw data and any scripts. This is where using computer code over clicking makes a huge difference. If the raw data and script are available, then it is simple for someone else to run the analysis later and see the decisions you made about the data quirks. Different scientists will make different decisions about each of those quirks. The most important thing is not which decision is made per se, but that the trail of breadcrumbs exists to allow a decision to be transparent. That may seem a little daunting. It is scary to have someone else see all of your decisions. But here’s the actual truth: The person who will benefit most from your transparent data and code is not another scientist. It is you. In two days, two months, or two years, you will eventually have to return to an old analysis. You’ll need it to wrap up that semester’s term paper or reanalyze something from your thesis. You will NOT NOT NOT NOT NOT remember what you have done, no matter how obvious it seemed when you were doing it. For that reason, having script that is reproducible will save you hours, maybe weeks, of otherwise wasted time. Trust us…just trust us. Except for JR, an English professor who doesn’t understand any of this. We assume he is currently pontificating about the literary importance of using salve versus halve in the writings of Chaucer (who uses neither word). JR has a large collection of feathered pens and prefers to write on low gloss paper sourced from the Pacific Northeast.↩︎ "],
["thinking-quantitatively.html", "5 Thinking Quantitatively 5.1 Learning Objectives 5.2 Why Statistics 5.3 Summary Statistics 5.4 Don’t forget that Quantitative Thinking includes “thinking” 5.5 Common Pitfalls in Statistical Inference", " 5 Thinking Quantitatively 5.1 Learning Objectives Understand why we use statistics Understand basic summary statistics Understand common pitfalls in statistical inference Lecture Link 1 - Basic Statistics Lecture Link 2 - Pitfalls 5.2 Why Statistics Statistics is a process of analyzing data to learn about a question of interest. We find that statistics can be daunting for undergraduate students. It was daunting for us as well. The goal of this book is not to teach you how to be a statistician. It is to teach you how to begin working with and understanding data as it pertains to scientific inquiry. The skills you learn here should allow you to read a scientific paper and not have to look up what a standard error is or what a confidence interval is or what the difference is between a median and a mean. A poorly kept secret in science is that you need a working understanding of statistics whether you use it formally or not. Consider a doctor who needs to prescribe a drug for disease X. There are three drugs on the market for this disease. The drugmakers have provided you with the following graphs showing how good their drugs are at treating this disease. ## Saving 7 x 5 in image Figure 5.1: Proportion of patients that recovered from a disease after taking one of three drugs. Each dot represents the outcome of a single experiment (i.e. trial). Figure above shows the result of twenty trials of each drug. For each trial, the drug makers calculated the percentage of patients that recovered from the disease after taking the drug. Which one should the doctor prescribe? For drugs A and B, several trials showed that 100% of patients that took the drug recovered. Those seem like good choices. For drug C, recoveries were all over the place. In some trials, less than half of the patients recovered after taking the drug. That doesn’t seem good. However, since the doctor took Inquiry and Analysis in Biology as an undergrad, they notice something odd about these data. The drug makers only report recoveries of people who took the drug. What about people who had the same disease but didn’t take a drug? In other words, what about the controls? The doctor asks for this information. Let’s look at the same graph, but now with the data for controls added. Figure 5.2: Proportion of patients that recovered from a disease after taking one of three drugs. Each dot represents the outcome of a single experiment (i.e. trial). In the figure above, the black dots are the same as before. The gray dots show the percent of people who recovered without taking the drug. Does this information change your perception of the benefits of taking either drug? In the first graph, it seemed obvious that drugs A and B were better than drug C, because most people recovered with those drugs. Adding the control data tells a different story. While it is true that most people recovered when taking drugs A and B, they also recovered without taking those drugs. For drug C, only ~25 to 75 percent of people recovered when taking it, but that percentage appears much higher than the percentage of people that recovered without taking the drug. In some trials, almost no one recovered without the drug. This complicates the decision of which drug to choose. Because our doctor took Inquiry and Analysis in Biology and later took biostatistics, they ask for further information. Instead of just looking at the data for each group, they want something more informative. For each trial, they subtract the percent that recovered when taking the drug from the percent that recovered when not taking the drug. Then they plot it. It looks like this. Figure 5.3: Proportion of patients that recovered from a disease after taking one of three drugs. Each dot represents the outcome of a single experiment (i.e. trial). Now we see a different story than the figure we started with. By displaying the differences in recovery, instead of the raw recovery rates, it now appears that drug C is a clear winner. In all but three trials, recovery rates were higher for people that took the drug compared to those that didn’t. So far, we have only plotted the data. We haven’t quantified anything yet, but by plotting the data and being self-critical of the ways in which we might be fooling ourselves, we have practiced quantitative reasoning. This process also illustrates a broader principle: statistics can not automate scientific decisions. Each of the plots above used statistical software and could be analyzed with a wide array of statistical models. But none of those models know about the experiment. They will all give a result, but it is up to you to interpret its importance. Plotting data is among the most important steps in any project. Plotting (aka making graphs, data visualization) does several things. 1) It reveals any obvious problems in data entry. 2) It shows trends in the data. 3) It revealss the experimental design. This last step is crucial. Deciding what to put on the x-axis versus the y-axis, how to label those axes, what range to put on the y-axis, what groups to label in the figure legend…these are just some of the choices you’ll make when plotting data. Students often do this step last, hoping to add a graph at the end to complete an assignment. Don’t do that. Plot early and often, even before you have data. If you know what the axes should be, and which groups will go side-by-side (like the gray and black dots in Figure X), then you have already crystalized nearly everything that you will later write about in the rest of your paper (see Figures First in the previous chapter). 5.3 Summary Statistics Now that we’ve plotted our results, the next step is to describe them using summary statistics. Summary statistics are numbers that describe some aspect of a data set. They include things like the mean, median, standard deviation, quantiles, minimum, and maximum. In combination with plotting, summary statistics are critical for communicating science. Summary statistics also provide a guide for how to verbally describe your results to your professor, colleague, friend, or whoever is trying to understand your science. You should aim to provide at least the following summary statistics for every important result. They are defined below along with the R function that calculates them in italics. Mean The central tendency of your data. calculated as the sum of the value of all data in a group divided by the number of data Standard Deviation The spread of your data. Let’s say you have 10 data points with a mean of 2 and a standard deviation of 0.5. Even though the mean is 2, very few individual data points will be exactly 2. In fact, none of them may be exactly 2. Instead, the data points will “deviate” from the mean. A standard deviation of 0.5 means that the average deviation from the mean is 0.5 absolute units from 2. We usually write this with +/- symbols (2 +/- 0.5), meaning that a typical data point might be anywhere from 2.5 to 1.5. Minimum The smallest value. Maximum The largest value. The code below will generate the data set used in Figure 3 above called drug_data - just copy it and run it. Don’t worry about interpreting it for now. Once we have a data set, we use the group_by() and summarize() functions to generate the summary statistics. ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 3 x 5 ## drug mean sd min max ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 drug_a 0.0315 0.303 -0.61 0.72 ## 2 drug_b -0.00950 0.150 -0.290 0.38 ## 3 drug_c 0.428 0.306 -0.18 0.9 That’s a lot of decimal places! Let’s clean it up a bit before moving on. Compare the code below to the code above. Can you see how we shortened the decimal places? Why did we keep two decimal places for the mean, but only 1 decimal place for everything else? ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 3 x 5 ## drug mean sd min max ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 drug_a 0.03 0.3 -0.6 0.7 ## 2 drug_b -0.01 0.1 -0.3 0.4 ## 3 drug_c 0.43 0.3 -0.2 0.9 Now we’ll add the mean and sd to the plot. Can you see how it is added in the code below? This looks pretty close to a finished product now. It has lots of information in the plot, including the raw data, the mean, and the standard deviation. By combining the summary statistics and the plot, we are ready to write a paragraph about this result. Across 20 trials, recovery rates were 0.43 +/- 0.3 points higher for groups that took drug C versus that took a placebo. Recovery ranged from -0.2 to 0.9. In comparison, recovery rates for drug A were only 0.03 +/- 0.3 points higher than placebo controls, and recovery rates for drug B were 0.01 +/- 0.1 points worse than placebo controls. However, direct comparison of these drugs is complicated by the fact that raw rates of recovery were highest for drugs A and B, in which nearly all patients recovered in both treatment and control groups. In contrast, recovery rates for drug C were ~50% in the treatment group, but only ~10% in the control. This suggest the potential that the trials were conducted on groups with different underlying probabilities of recovery. 5.4 Don’t forget that Quantitative Thinking includes “thinking” A statistical model alone will not answer your scientific question. The work flow presented above is not a formula for success in every case. Each problem you attempt to solve as a scientist is unique and will require you to make judgment calls. Statistics can help us to justify those judgments, making our decisions less susceptible to personal bias, but they cannot eliminate subjectivity. The point of Quantitative Thinking is not to replace critical thought with computer generated outputs. It is to use the tools of statistics and experimental design to prevent us from fooling ourselves. As Richard Feynman said: “The first principal [of science] is to not fool yourself, and you are the easiest person to fool.” 5.5 Common Pitfalls in Statistical Inference Here are some easy ways to fool yourself in science and quantitative thinking. Spurious correlations Assuming that correlations reflect causation. Forgetting about hidden variables The plot below is from real data. How do you interpret this result? ## `geom_smooth()` using formula &#39;y ~ x&#39; The figure shows a clear positive correlation between the divorce rate and the number of Waffle Houses (McElreath 2015). In this case, it is obvious (hopefully) that Waffle Houses are probably not causing divorces. What’s going on? The states that are labeled are all in the South, where Waffle Houses are common. People also happen to get married earlier in the South, which helps to explain the higher than average divorce rates there. Here’s another less obvious example. ## `geom_smooth()` using formula &#39;y ~ x&#39; The figure shows a positive relationship between a country’s gross domestic product (GDP) and its life expectancy in 2007. Each dot is a country. In our experience, this correlation is a common one for students to study. They often interpret the result as confirming a benefit of economic activity with how long people live, and conclude that countries can improve life-expectancy simply by improving economic activity. But this represents a similar fallacy as the Waffle House-Divorce example. An easy way to see this is to check death certificates. If we did that (we didn’t, but we think we’re safe here), we would probably not find a cause of death that says “Died due to low GDP”. Just like Waffle Houses are associated with “Southerness” and “Southerness” is associated with early age at marriage and early age at marriage leads to higher divorce rates, GDP is associated with its own confounding variable of health care infrastructure. That is itself a large and difficult-to-define metric, but it is closer to explaining the positive correlation between GDP and life expectancy. It is certainly true that countries with higher GDP’s tend to also have better health outcomes because they have better health infrastructure. The trick is to think about the actual steps that have to happen for GDP to translate to longer life-expectancy. Each country will make individual choices along those steps, and each choice has the potential to sever the link between GDP and efficient health spending. There is nothing wrong with studying the statistical relationship between GDP and life expectancy. Just be careful in assuming that simply improving GDP will automatically improve life-expectancy. 5.5.0.1 Preventing mistakes with spurious correlations Use similar quantitative reasoning as the doctor did with the drug company results. In essence, ask how an initial result might be missing something crucial (like a control or a confounder). This is especially important if the initial result is something you were expecting to see. If you were expecting to see a positive correlation between x and y and you found it, that’s great. But don’t let that result prevent you from thinking critically about other ways that your result could arise. Negative Results as Failures Assuming that your study “failed” because it did not support your hypothesis You form a hypothesis, expect an outcome, collect data, and find…nothing. No relationship. Nada. What do you conclude from this? A common mistake is to declare a “failed” experiment. Some students try to start a new project from scratch, just so they can report a “positive” outcome. Don’t do that! An unwritten rule of science is that our failures often lead to the most interesting research. After all, you probably did a study thinking you knew the answer. When it fails, it means that something that most scientists might predict is not quite right. Consider geocentrism. When scientists in the 1600’s found that their calculations of the planets and stars were wrong, that was not a failure (well, it was a failure of the mathematical models themselves, but not of the scientific endeavor writ large). Instead, those bad predictions eventually revealed that something that most humans believed (earth at the center of the universe) was wrong. Being wrong did not mean that those scientists were bad scientists. It was perfectly reasonable to expect that the earth was stationary and everything else moved around it. In my own research (Wesner’s), a failure lead to a new area of study. We wanted to know how metal contamination from streams would affect insects that lived in those streams. We knew that young insects had high metal concentrations and assumed that the adults would too. We even wrote several grants that made that assumption, asking for money to study how those metals in adult insects would impact birds that fed on them. So we collected some adults from contaminated streams and measured the concentration of metals in them. We were shocked. Even though they came from contaminated streams and the larvae in those streams had high metal concentrations, the adults did not. They looked fine. We were wrong. There did not seem to be any risk of metal contamination to birds. This was embarrassing, but it also lead to a different line of research. We read the literature and conducted experiments. We determined that lots of contaminants are lost during metamorphosis. But during that loss, many insects also die. It’s too stressful. So the main risk of metals that we studied was not that metals would get into birds and prevent their reproduction. The main risk was that metals would prevent insects from emerging altogether, thereby leading to less food for birds. Without this initial “failure”, we never would have discovered the actual links between metal contamination in streams and risks to riparian birds. 5.5.0.2 Preventing mistakes with negative results Treat them as an opportunity to learn more. If your hypothesis was not supported, explore the reasons why. Do you predictor and response variables actually measure the quantities of your hypothesis or are they a proxy? If they’re a proxy, maybe they don’t measure what you think they do. Maybe the negative results is robust and it challenges conventional wisdom. That’s exciting! What are the implications of a hypothesis that didn’t pan out? Explore those and suggest how future scientists should proceed now that we know that a given hypothesis isn’t always supported. Ecological Fallacy Using aggregate data to infer something about individuals Extreme obesity is a global public health concern that is defined as a body mass index of 40 kg/m2 or more. Individuals in this category have increased rates of mortality, often due to increased rates of heart disease, cancer, stroke and other ailments (???). Let’s visualize the relationship between obesity and life-expectancy across countries. In the plot below, each dot is a different country. The line represents a linear regression between the two variables. ## Parsed with column specification: ## cols( ## country = col_character(), ## obesity_rate_perc_pop = col_double() ## ) ## Parsed with column specification: ## cols( ## .default = col_double(), ## country = col_character() ## ) ## See spec(...) for full column specifications. ## Joining, by = &quot;country&quot; ## `geom_smooth()` using formula &#39;y ~ x&#39; Is this what you expected? This seems like a paradox. Decades of studies clearly show that extreme obesity is linked with poor health outcomes and increased mortality. The plot above appears to contradict this. Countries with a higher percentage of obese people also tend to have higher life expectancy. This is an example of the ecological fallacy, which states that we cannot use aggregate data to infer something about individuals. For example, Kuwait has a high obesity rate of ~38% and a high life-expectancy of ~79 years. But those numbers represent averages of about 4 million individuals. If we were to assess a sample of individuals within Kuwait, then we would expect the pattern that we initially hypothesized - at the individual level, extreme obesity is negatively associated with life-expectancy, but at the country-level the pattern is reversed. As you might expect by now, there are also other reasons to explain these associations, such as hidden variables. For example, look at the plot again, but now with information on GDP per capita. ## Parsed with column specification: ## cols( ## country = col_character(), ## obesity_rate_perc_pop = col_double() ## ) ## Parsed with column specification: ## cols( ## .default = col_double(), ## country = col_character() ## ) ## See spec(...) for full column specifications. ## Joining, by = &quot;country&quot; ## Joining, by = &quot;country&quot; ## `geom_smooth()` using formula &#39;y ~ x&#39; This is the same data, but now a third variable is presented, showing GDP per capita (in US 2007 Dollars). The scatter of the dots is non-random in the sense that countries with large GDP tend to be clustered in areas of both high life-expectancy and higher obesity rates. 5.5.0.3 Preventing the ecological fallacy mistake Relate your hypotheses and explanations to the level of your data. For example: What We Initially Wanted to Study How does obesity affect survival? What We Actually Studied What is the correlation between obesity rates and life expectancy among countries? Data Level Countries Faulty Description Individuals with extreme obesity live longer Correct Description At the country level, there is a positive statistical correlation between obesity rates and life expectancy. "],
["data-visualization.html", "6 Data Visualization 6.1 Learning Objectives", " 6 Data Visualization 6.1 Learning Objectives Understand the components of a graph Understand best practices in graph designs Lecture Link What makes a good graph? According to Edward Tufte (Tufte and Graves-Morris 1983), it is this: …that which gives the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space …graphical excellence requires telling the truth about the data Edward Tufte - The Visual Display of Quantitative Information We might consider these “high-level” guideposts to data visualization. It is tempting to think of this advice as applying only to modern scientific approaches, since anyone can create a graph on a computer. But Tufte’s book is almost 40 years old. It is a masterpiece of data visualization that is as relevant today as it was in 1983. Tufte includes examples that extend back centuries. The principles that we try to apply in this book are not new. They are simply extensions of a long history of the study of how to best display data. On a more fundamental level, we want to first focus on the basic components of common graphs. A graph is a like a map whose coordinates are defined by cells in a table. It typically contains a vertical y-axis and a horizontal x-axis. The data are added to the graph by reading reading from columns in a table. In the example below, the data table has two columns corresponding to location data (lat = latitude, long = longitude). It is easy to see how this information would “map” to coordinates on a graph. The x-coordinates would be longitude and the y-coordinates would be latitude. Each pair of x-y coordinates would be a dot. Like this: Figure 6.1: a) First six rows of data, b) The same data plotted on an x-y coordinate with latitude (lat) on the y-axis and longitude (long) on the x-axis, c) The same plot, but with polygons of US States added for context. Why make a graph? The table contains paired latitude and longitude coordinates, but unless you’re a savant at geography, it might not be clear how the coordinates are related. By plotting the data, we are able to see patterns that would be difficult or impossible to see in the table. For example, the dots on the left side of (b) are more evenly spaced than the dots on the right side of (b). There are also some visual outliers, like the dot in the lower right, upper left, and lower left. There’s nothing wrong with visual outliers. You’ll see them in every graph you plot. But we would want to explore a little to see what they are. For example, by adding a polygon of US states, it becomes immediately clear what we’re looking at. The lower right “outlier” isn’t an outlier at all (We’ll leave the jokes about Florida unsaid). There are still two dots that don’t have states surrounding them - Alaska and Hawaii. These are still like outliers, but we intuitively know what they are by plotting. None of that information is in the table by itself. 6.1.1 Basic Components of a Graph Nearly all graphs share some basic features. y-axis - Vertical axis. Often used to represent the response variable. x-axis - Horizontal axis. Often used to represent the predictor variable. coordinates - The x and y axis together form the coordinates of the plot. data - The values of y for each value of x. Commonly shown as points. colors - Used to distinguish different groups of data. Can be used to represent a separate response variable. shapes - Used to distinguish different groups of data. Can be used to represent a separate response variable. lines - Often used to show trends in the data. These basic components form an enormous array of visualizations. Here’s an example using the iris data set, which gives measures of flowers for three different species. It is included with R. Figure 6.2: a) First six rows of the iris data set, b) Scatterplot of the iris data, c) The same plot, but with a linear regression line for context. The blue line is the mean and the shading is the standard error of the mean. Color is also added to show a third variable for species. The table and figures above follow the same sequence as the map before. We start with a table of data, where each row is an individual observation with information on petal length, petal width, and flower species. We then make an initial scatter plot, showing patterns that are hard or impossible to see just by looking at the table. Finally, we add a regression line and some colors for context. Even though these graphs are for flowers and the previous graphs were for states, they share the same simple components, derived from data. We tell the graphing software where to find the data (iris), where to find the column for the y-axis (Petal.Length), the x-axis (Petal.Width), and where to find the column for color (Species). If we wanted to add another layer, like size of the individual, we would need to collect that data and simply add it as a fourth column in the data set. 6.1.2 Best Practices We see bad graphs all the time, from scientists at all levels (undergrad to Professor). Here are some common ways to make a bad graph. Recipe for a bad graph Make the font really small Give really vague names to the axes Use lots of colors, particularly those that are impossible for color-blind people to distinguish Don’t save the graph itself, just take a screenshot of it Paste it into your paper and pull the corners so the text is stretched Recipe for a better graph Make the font readable in its final destination. Just because the font size is fine in R or Excel doesn’t mean it will be fine when you import it to your paper Give informative names to the axes (e.g., “Income per capita (US$)” instead of “Wealth”) Choose color-blind friendly colors or try grayscale first https://www.tableau.com/about/blog/2016/4/examining-data-viz-rules-dont-use-red-green-together-53463 Save the graph in a standard format, like .jpg, .png, or .svg If you’re writing in Word, use the Import button in Word to import your graph. Don’t copy and paste. These simple steps will not ensure a good graph, but they will ensure that your graph is readable in its final form. Here’s a comparison: Bad Graph Better Graph These are the same data sets in two different graphs. The first one violates most of the rules for a bad graph (or follows most of the rules, I guess). The second one is better. It isn’t pixelated and the text isn’t stretched. The colors are visible even to a colorblind person (using scale_color_colorblind() from the ggthemes package). The axis labels are a bit more informative, giving the units for the sepal widths and lengths. While this may seem like a trivial and obvious comparison, the first version is one we see all the time in student papers, and even in manuscripts submitted by PhDs. The easiest way to avoid this problem is to take the following steps: Create the graph in your software Save it as a high-resolution figure in a common format, like .jpg, .png, or .svg. Import it to your text document using the import button If it doesn’t look right, delete it from the text document Return to step 1 and edit as needed Using ggplot in R, we can save a high resolution version of our graph with the ggsave() function. Saving a high resolution graph The code above makes a graph called “my_graph”, calls the graph in R to view it, and then saves it as a .jpg with the ggsave() function. The ggsave() function has several options image type - By adding “.jpg” to the end of our graph name in the file = … statement, we are creating a .jpg. To create a .png, just add “.png” instead. ggsave() can create 10 different file types - .png, .eps, .ps, .tex, .pdf, .jpg, .tiff, .bmp, .svg, or .wmf. Choose the one that works best for you. dpi - dots per inch. The higher then number, the higher the resolution. However, increasing dpi also increases the file-size of your plot, which can make things really slow depending on your computer. A dpi of 500 or 600 is good for nearly all uses. width - This sets the width of your graph. height - This sets the height of your graph. units - This sets the units for width and height. We put units = \"in\" above, which means that we’re saving this graph to an expected size of 6x6 inches. If we set units to “cm”, then it would be 6x6 cm and so on. Pick whatever measurement unit you are most comfortable with. We like inches because it is easy to imagine what a 6x6 inch graph would look like on a standard piece of 8x11.5 in paper. And because we grew up in the US, so the metric system is not as intuitive for us. Nash, John C. 2008. “Teaching Statistics with Excel 2007 and Other Spreadsheets.” Computational Statistics &amp; Data Analysis 52 (10): 4602–6. https://doi.org/10.1016/j.csda.2008.03.008. Tufte, Edward R, and Peter R Graves-Morris. 1983. The Visual Display of Quantitative Information. Vol. 2. 9. Graphics press Cheshire, CT. Wesner, Jeff S, Dan Van Peursem, Jose Flores, Yuhlong Lio, and Chelsea Wesner. 2020. “Forecasting Hospitalizations Due to COVID-19 in South Dakota, USA.” medRxiv. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the Tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. "]
]
